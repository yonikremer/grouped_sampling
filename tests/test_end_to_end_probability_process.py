# Generated by CodiumAI

import torch

from src.grouped_sampling.end_to_end_probability_processor import (
    EndToEndProbabilityProcessor,
)
from src.grouped_sampling.top_k import TopKProbabilityProcessor
from src.grouped_sampling.top_p import TopPProbabilityProcessor

"""
Code Analysis

Main functionalities:
The EndToEndProbabilityProcessor class is responsible for processing probabilities by applying multiple probability processors in sequence. It takes in a tensor of probabilities and applies the specified probability processors in order to modify the probabilities. The class can apply both TopPProbabilityProcessor and TopKProbabilityProcessor processors, depending on the values of the top_p and top_k parameters.

Methods:
- __init__(self, minimum_tokens_to_keep: int = 1, top_p: float = 1.0, top_k: int = 0): Initializes the EndToEndProbabilityProcessor object with the specified parameters. It creates a list of probability processors to apply based on the values of top_p and top_k.
- __call__(self, probs: torch.Tensor) -> torch.Tensor: Applies the list of probability processors to the input tensor of probabilities in sequence. Returns the modified tensor.

Fields:
- processors: A list of probability processors to apply to the input tensor of probabilities. The list is created based on the values of top_p and top_k parameters passed to the constructor.
"""


class TestEndToEndProbabilityProcessor:
    #  Tests that the class can be instantiated with default arguments
    def test_default_arguments(self):
        processor = EndToEndProbabilityProcessor()
        assert isinstance(processor, EndToEndProbabilityProcessor)
        assert len(processor.processors) == 0

    #  Tests that the class can be instantiated with valid arguments
    def test_valid_arguments(self):
        processor = EndToEndProbabilityProcessor(
            minimum_tokens_to_keep=2, top_p=0.5, top_k=3
        )
        assert isinstance(processor, EndToEndProbabilityProcessor)
        assert len(processor.processors) == 2
        assert processor.processors[0].minimum_tokens_to_keep == 2
        assert processor.processors[0].top_p == 0.5
        assert processor.processors[1].top_k == 3
        assert isinstance(processor.processors[0], TopPProbabilityProcessor)
        assert isinstance(processor.processors[1], TopKProbabilityProcessor)

    #  Tests that the __call__ method returns the input tensor when no processors are applied
    def test_no_processors(self):
        processor = EndToEndProbabilityProcessor()
        input_tensor = torch.tensor(
            [[[0.1, 0.2, 0.3, 0.4], [0.4, 0.3, 0.2, 0.1], [0.1, 0.2, 0.3, 0.4]]]
        )
        output_tensor = processor(input_tensor)
        assert torch.allclose(input_tensor, output_tensor)

    #  Tests that the __call__ method returns the expected tensor when applying TopPProbabilityProcessor
    def test_top_p_processor(self):
        processor = EndToEndProbabilityProcessor(minimum_tokens_to_keep=2, top_p=0.5)
        input_tensor = torch.tensor(
            [[[0.1, 0.2, 0.3, 0.4], [0.4, 0.3, 0.2, 0.1], [0.1, 0.2, 0.3, 0.4]]]
        )
        expected_output = torch.tensor(
            [[[0.0, 0.0, 0.3, 0.4], [0.4, 0.3, 0.0, 0.0], [0.0, 0.0, 0.3, 0.4]]]
        )
        expected_output /= expected_output.sum(dim=-1).unsqueeze(-1)
        output_tensor = processor(input_tensor)
        assert torch.allclose(expected_output, output_tensor)

    #  Tests that the __call__ method returns the expected tensor when applying TopKProbabilityProcessor
    def test_top_k_processor(self):
        processor = EndToEndProbabilityProcessor(top_k=2)
        input_tensor = torch.tensor(
            [[[0.1, 0.2, 0.3, 0.4], [0.4, 0.3, 0.2, 0.1], [0.1, 0.2, 0.3, 0.4]]]
        )
        expected_output = torch.tensor(
            [[[0.0, 0.0, 0.3, 0.4], [0.4, 0.3, 0.0, 0.0], [0.0, 0.0, 0.3, 0.4]]]
        )
        expected_output /= expected_output.sum(dim=-1).unsqueeze(-1)
        output_tensor = processor(input_tensor)
        assert torch.allclose(expected_output, output_tensor)

    #  Tests that the __call__ method returns the expected tensor when applying both TopPProbabilityProcessor and TopKProbabilityProcessor
    def test_top_p_and_top_k_processors(self):
        processor = EndToEndProbabilityProcessor(
            minimum_tokens_to_keep=2, top_p=0.5, top_k=2
        )
        input_tensor = torch.tensor(
            [[[0.1, 0.2, 0.3, 0.4], [0.4, 0.3, 0.2, 0.1], [0.1, 0.2, 0.3, 0.4]]]
        )
        expected_output = torch.tensor(
            [[[0.0, 0.0, 0.3, 0.4], [0.4, 0.3, 0.0, 0.0], [0.0, 0.0, 0.3, 0.4]]]
        )
        expected_output /= expected_output.sum(dim=-1).unsqueeze(-1)
        output_tensor = processor(input_tensor)
        assert torch.allclose(expected_output, output_tensor)

    # Tests that the class doesn't use any extra GPU memory
    def test_doesnt_use_extra_gpu_memory(self):
        processor = EndToEndProbabilityProcessor(
            minimum_tokens_to_keep=2, top_p=0.5, top_k=2
        )
        probs = torch.tensor(
            [[[0.1, 0.2, 0.3, 0.4], [0.4, 0.3, 0.2, 0.1]]], device="cuda:0"
        )
        with torch.cuda.device(0):
            start_memory = torch.cuda.memory_allocated(0)
            processor(probs)
            assert torch.cuda.memory_allocated(0) == start_memory

    # Tests that all the vectors in the output tensor sum to 1
    def test_output_tensor_sums_to_1(self):
        processor = EndToEndProbabilityProcessor(
            minimum_tokens_to_keep=2, top_p=0.5, top_k=2
        )
        probs = torch.tensor(
            [[[0.1, 0.2, 0.3, 0.4], [0.4, 0.3, 0.2, 0.1]]], device="cuda:0"
        )
        output_tensor = processor(probs)
        assert torch.allclose(
            output_tensor.sum(dim=-1), torch.ones_like(output_tensor.sum(dim=-1))
        )
