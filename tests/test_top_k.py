# Generated by CodiumAI

import pytest
import torch

from src.grouped_sampling.top_k import TopKProbabilityProcessor

"""
Code Analysis

Main functionalities:
The TopKProbabilityProccesor class is used for processing probabilities by keeping only the top k values and setting the rest to 0. It inherits from the ProbabilityProccesor abstract class and overrides its __call__ method to implement the top-k processing. The class keeps the top k values for each row in the last dimension of the input tensor and sets the rest to 0. This is useful for tasks such as language modeling, where we want to generate the most likely next word given a sequence of previous words.

Methods:
- __init__(self, top_k: int, device: torch.device): Constructor method that initializes the top_k field and calls the super constructor of ProbabilityProccesor to set the device field.
- __call__(self, probs: torch.Tensor) -> torch.Tensor: Overrides the __call__ method of ProbabilityProccesor to implement the top-k processing. It takes a tensor of shape (batch_size, output_length, vocab_size) as input and returns a tensor of the same shape with the top k values for each row in the last dimension and the rest set to 0.

Fields:
- top_k: An integer field that represents the number of top values to keep for each row in the last dimension of the input tensor.
- device: A torch.device field that represents the device on which the tensor operations will be performed. It is inherited from the ProbabilityProccesor abstract class.
"""


class TestTopKProbabilityProcessor:
    #  Tests that the function keeps the top k values for each row in the last dimension and sets the rest to 0 for a tensor of shape (batch_size, output_length, vocab_size) with all positive values
    def test_top_k_positive_values(self):
        top_k = 3
        processor = TopKProbabilityProcessor(top_k)
        probs = torch.tensor([
            [[0.1, 0.2, 0.3, 0.4], [0.4, 0.3, 0.2, 0.1]],
            [[0.4, 0.3, 0.2, 0.1], [0.1, 0.2, 0.3, 0.4]],
        ])
        expected_output = torch.tensor([
            [[0.0, 0.2, 0.3, 0.4], [0.4, 0.3, 0.2, 0.0]],
            [[0.4, 0.3, 0.2, 0.0], [0.0, 0.2, 0.3, 0.4]],
        ])
        output = processor(probs)
        assert torch.allclose(output, expected_output)

    #  Tests that the function keeps the top k values for each row in the last dimension and sets the rest to 0 for a tensor of shape (batch_size, output_length, vocab_size) with some zero values
    def test_top_k_some_zero_values(self):
        top_k = 2
        processor = TopKProbabilityProcessor(top_k)
        probs = torch.tensor([
            [[0.1, 0.2, 0.0, 0.4], [0.0, 0.3, 0.2, 0.1]],
            [[0.4, 0.3, 0.2, 0.1], [0.1, 0.0, 0.3, 0.4]],
        ])
        expected_output = torch.tensor([[[0, 0.2, 0, 0.4], [0, 0.3, 0.2, 0]],
                                        [[0.4, 0.3, 0, 0], [0, 0, 0.3, 0.4]]])
        output = processor(probs)
        assert torch.allclose(output, expected_output)

    #  Tests that the function raises a ValueError for a tensor with some negative values
    def test_top_k_some_negative_values(self):
        top_k = 2
        processor = TopKProbabilityProcessor(top_k)
        probs = torch.tensor([
            [[0.1, -0.2, -0.3, 0.4], [0.0, -0.3, -0.2, 0.1]],
            [[-0.4, -0.3, 0.2, 0.1], [0.1, -0.2, -0.3, 0.4]],
        ])
        with pytest.raises(ValueError):
            processor(probs)

    #  Tests that the function raises a ValueError for a tensor with some values greater than one
    def test_top_k_some_values_greater_than_one(self):
        top_k = 2
        processor = TopKProbabilityProcessor(top_k)
        probs = torch.tensor([
            [[0.1, 1.2, 1.3, 0.4], [1.5, 0.3, 0.2, 0.1]],
            [[1.4, 0.3, 0.2, 0.1], [0.1, 1.2, 1.3, 0.4]],
        ])
        with pytest.raises(ValueError):
            processor(probs)

    #  Tests that the function raises a value error for a tensor with all values equal to 1
    def test_top_k_all_values_equal_to_one(self):
        top_k = 2
        processor = TopKProbabilityProcessor(top_k)
        probs = torch.ones((2, 2, 4))
        with pytest.raises(ValueError):
            processor(probs)

    #  Tests that the function keeps the top k values for each row in the last dimension and sets the rest to 0 for a tensor of shape (batch_size, output_length, vocab_size) with some NaN values
    def test_top_k_some_nan_values(self):
        top_k = 2
        processor = TopKProbabilityProcessor(top_k)
        probs = torch.tensor([
            [[0.1, float("nan"), 0.3, 0.4], [0.4, 0.3, 0.2, 0.1]],
            [[0.4, 0.3, 0.2, 0.1], [0.1, float("nan"), 0.3, 0.4]],
        ])
        with pytest.raises(ValueError):
            processor(probs)

    #  Tests that the function keeps the top k values for each row in the last dimension and sets the rest to 0 for a tensor of shape (batch_size, output_length, vocab_size) with some Inf values
    def test_top_k_some_inf_values(self):
        top_k = 2
        processor = TopKProbabilityProcessor(top_k)
        probs = torch.tensor([
            [[0.1, float("inf"), 0.3, 0.4], [0.4, 0.3, 0.2, 0.1]],
            [[0.4, 0.3, 0.2, 0.1], [0.1, float("inf"), 0.3, 0.4]],
        ])
        with pytest.raises(ValueError):
            processor(probs)

    #  Tests that the function sets all values to 0 for a tensor of shape (batch_size, output_length, vocab_size) with all zero values
    def test_top_k_all_zero_values(self):
        top_k = 2
        processor = TopKProbabilityProcessor(top_k)
        probs = torch.zeros((2, 2, 4))
        expected_output = torch.zeros((2, 2, 4))
        output = processor(probs)
        assert torch.allclose(output, expected_output)

    #  Tests that the function sets all values to 0 for a tensor of shape (batch_size, output_length, vocab_size) with all NaN values
    def test_top_k_all_nan_values(self):
        top_k = 2
        processor = TopKProbabilityProcessor(top_k)
        probs = torch.tensor([
            [
                [float("nan"),
                 float("nan"),
                 float("nan"),
                 float("nan")],
                [float("nan"),
                 float("nan"),
                 float("nan"),
                 float("nan")],
            ],
            [
                [float("nan"),
                 float("nan"),
                 float("nan"),
                 float("nan")],
                [float("nan"),
                 float("nan"),
                 float("nan"),
                 float("nan")],
            ],
        ])
        with pytest.raises(ValueError):
            processor(probs)

    # Tests that the class doesn't use any extra GPU memory
    def test_doesnt_use_extra_gpu_memory(self):
        processor = TopKProbabilityProcessor(2)
        probs = torch.tensor([[[0.1, 0.2, 0.3, 0.4], [0.4, 0.3, 0.2, 0.1]]],
                             device="cuda:0")
        with torch.cuda.device(0):
            start_memory = torch.cuda.memory_allocated(0)
            processor(probs)
            assert torch.cuda.memory_allocated(0) == start_memory
