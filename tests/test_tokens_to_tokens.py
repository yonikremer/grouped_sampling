
# Generated by CodiumAI

import pytest
import torch
from transformers import GenerationConfig, AutoConfig

from src.grouped_sampling import GroupedGenerationUtils, NoRepetitionPenalty
from src.grouped_sampling.logits_vec_to_token import LogitVectorToTokenPipeLine
from src.grouped_sampling.model import get_model
from src.grouped_sampling.tokenizer import get_tokenizer, get_end_of_text_id, get_padding_id
from src.grouped_sampling.tokens_to_tokens_pipeline import TokensToTokensPipeLine

"""
Code Analysis

Main functionalities:
The TokensToTokensPipeLine class is a pipeline that takes a LongTensor of tokens as input and returns a LongTensor of tokens. It achieves this by using a wrapped model to generate logits matrices and a LogitVectorToTokenPipeLine object to convert these matrices to token ids.

Methods:
- __init__: Initializes the TokensToTokensPipeLine object with a LogitVectorToTokenPipeLine object and a wrapped model.
- call_single_sequence: Takes a LongTensor of token ids and an output length and returns a LongTensor of token ids generated by the wrapped model.
- call_batch: Takes a batch of LongTensors of token ids and an output length and returns a batch of LongTensors of token ids generated by the wrapped model.

Fields:
- logits_vec_to_token_pipeline: A LogitVectorToTokenPipeLine object used to convert logits matrices to token ids.
- wrapper_model: A GroupedGenerationUtils object used to generate logits matrices from token ids.
"""
class TestTokensToTokensPipeLine:
    #  Tests that call_single_sequence returns a LongTensor of tokens for a single sequence input
    def setup_method(self):
        test_tokenizer = get_tokenizer("fxmarty/tiny-llama-fast-tokenizer")
        test_config = AutoConfig.from_pretrained("fxmarty/tiny-llama-fast-tokenizer")
        test_wrapper_model = GroupedGenerationUtils(
            model=get_model("fxmarty/tiny-llama-fast-tokenizer"),
            max_input_len=1028,
            end_of_sentence_id=get_end_of_text_id(test_tokenizer, test_config),
            padding_id=get_padding_id(test_tokenizer),
            vocab_size=test_tokenizer.vocab_size,
            repetition_penalty_strategy=NoRepetitionPenalty(),
            end_of_sentence_stop=True,
        )
        test_logit_to_token_pipeline = LogitVectorToTokenPipeLine(GenerationConfig())
        self.test_tokens_to_tokens_pipeline = TokensToTokensPipeLine(test_logit_to_token_pipeline, test_wrapper_model)

    def test_single_sequence_returns_tensor(self):
        input_ids = torch.tensor([[1, 2, 3], [4, 5, 6]])
        output_length = 2
        result = self.test_tokens_to_tokens_pipeline.call_single_sequence(input_ids[0], output_length)
        assert isinstance(result, torch.Tensor)
        assert result.shape == (2,)
        assert result.dtype in (torch.int64, torch.int32, torch.int16, torch.int8, torch.int, torch.long)

    #  Tests that call_batch returns a LongTensor of tokens for a batch input
    def test_batch_returns_tensor(self):
        input_ids = torch.tensor([[1, 2, 3], [4, 5, 6]])
        output_length = 2
        result = self.test_tokens_to_tokens_pipeline.call_batch(input_ids, output_length)
        assert isinstance(result, torch.Tensor)
        assert result.shape == (2, 2)
        assert result.dtype in (torch.int64, torch.int32, torch.int16, torch.int8, torch.int, torch.long)

    #  Tests that ValueError is raised if token_ids is not a 2D long tensor
    def test_value_error_if_token_ids_not_2d(self):
        input_ids = torch.tensor([1, 2, 3])
        output_length = 2
        with pytest.raises(ValueError):
            self.test_tokens_to_tokens_pipeline.call_batch(input_ids, output_length)

    #  Tests that ValueError is raised if token_ids is empty
    def test_value_error_if_token_ids_empty(self):
        input_ids = torch.tensor([])
        output_length = 2
        with pytest.raises(ValueError):
            self.test_tokens_to_tokens_pipeline.call_batch(input_ids, output_length)

    #  Tests that TypeError is raised if output_length is not an int
    def test_type_error_if_output_length_not_int(self):
        input_ids = torch.tensor([[1, 2, 3], [4, 5, 6]])
        output_length = '2'
        with pytest.raises(TypeError):
            self.test_tokens_to_tokens_pipeline.call_batch(input_ids, output_length)

    #  Tests that ValueError is raised if output_length is not a positive int
    def test_value_error_if_output_length_not_positive(self):
        input_ids = torch.tensor([[1, 2, 3], [4, 5, 6]])
        output_length = -2
        with pytest.raises(ValueError):
            self.test_tokens_to_tokens_pipeline.call_batch(input_ids, output_length)
