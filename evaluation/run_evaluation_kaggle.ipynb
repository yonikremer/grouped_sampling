{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyP5R0XJb8yjyEHCDIXSM/Sf",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Configure the project"
   ],
   "metadata": {
    "id": "8aa3ZKSzG2kB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os, shutil, sys\n",
    "\n",
    "if os.path.exists(\"./final_project\") and os.path.isdir(\"./final_project\"):\n",
    "    shutil.rmtree(\"./final_project\")\n",
    "os.system(\"git clone https://github.com/yonikremer/final_project.git\")\n",
    "\n",
    "sys.path.append('/content/final_project');"
   ],
   "metadata": {
    "id": "L4YZc7WyH8pi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "%pip install -r -q ./final_project/evaluation/evaluation_requirements.txt\n",
    "%pip install -r -q ./final_project/project_requirements.txt"
   ],
   "metadata": {
    "id": "kHOB4G7SjYG5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run the evaluation script"
   ],
   "metadata": {
    "id": "RaC1h64LHBK8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%run /content/final_project/evaluation/evaluate_translation.py"
   ],
   "metadata": {
    "id": "aPSYx2-beXfR",
    "outputId": "66bba5f9-642c-4475-dc09-860be56be9f9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 800
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: keras, tensorflow, sklearn, tensorboard, torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/yonikremer/grouped-sampling-evaluation/da9f01e35c7746bbb405ccf2d07176a3\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     generation_type : GenerationType.TOP_P\n",
      "COMET INFO:     group_size      : 8\n",
      "COMET INFO:     model_name      : facebook/opt-125m\n",
      "COMET INFO:     temperature     : 1.0\n",
      "COMET INFO:     top_k           : 1\n",
      "COMET INFO:     top_p           : 0.5\n",
      "COMET INFO: ---------------------------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "starting experiment\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: keras, tensorflow, sklearn, tensorboard, torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET ERROR: Failed to calculate active processors count. Fall back to default CPU count 1\n",
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/yonikremer/grouped-sampling-evaluation/f41abc45d41647f6a0640f38e0982338\n",
      "\n",
      "WARNING:datasets.builder:Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/ar-cs/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/ar-cs/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-fb269e8edfe20f68.arrow\n",
      "\n",
      "  0%|          | 0/52128 [19:50<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/content/final_project/evaluation/evaluate_translation.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    125\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0m__name__\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"__main__\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 127\u001B[0;31m     \u001B[0mmain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/content/final_project/evaluation/evaluate_translation.py\u001B[0m in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m    121\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mcurr_text_generator\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mgenerate_text_generators\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    122\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"starting experiment\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 123\u001B[0;31m         \u001B[0mrun_experiment\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcurr_text_generator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    124\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    125\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/final_project/evaluation/evaluate_translation.py\u001B[0m in \u001B[0;36mrun_experiment\u001B[0;34m(generator)\u001B[0m\n\u001B[1;32m    109\u001B[0m         \u001B[0mmy_evaluator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mMETRIC_KWARGS\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m\"lang\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mlanguage2\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m         scores1 = my_evaluator.compute(model_or_pipeline=generator,\n\u001B[0;32m--> 111\u001B[0;31m                                        data=processed_sub_set, input_column=language1, label_column=language2)\n\u001B[0m\u001B[1;32m    112\u001B[0m         \u001B[0mhandler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog_sub_experiment\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mscores1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m         \u001B[0mmy_evaluator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mMETRIC_KWARGS\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m\"lang\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mlanguage1\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/evaluate/evaluator/text2text_generation.py\u001B[0m in \u001B[0;36mcompute\u001B[0;34m(self, model_or_pipeline, data, subset, split, metric, tokenizer, strategy, confidence_level, n_resamples, device, random_state, input_column, label_column, generation_kwargs)\u001B[0m\n\u001B[1;32m    246\u001B[0m             \u001B[0mrandom_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrandom_state\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    247\u001B[0m             \u001B[0minput_column\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minput_column\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 248\u001B[0;31m             \u001B[0mlabel_column\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlabel_column\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    249\u001B[0m         )\n\u001B[1;32m    250\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/evaluate/evaluator/text2text_generation.py\u001B[0m in \u001B[0;36mcompute\u001B[0;34m(self, model_or_pipeline, data, subset, split, metric, tokenizer, strategy, confidence_level, n_resamples, device, random_state, input_column, label_column, generation_kwargs)\u001B[0m\n\u001B[1;32m    105\u001B[0m             \u001B[0mrandom_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrandom_state\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    106\u001B[0m             \u001B[0minput_column\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minput_column\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 107\u001B[0;31m             \u001B[0mlabel_column\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlabel_column\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    108\u001B[0m         )\n\u001B[1;32m    109\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/evaluate/evaluator/base.py\u001B[0m in \u001B[0;36mcompute\u001B[0;34m(self, model_or_pipeline, data, subset, split, metric, tokenizer, feature_extractor, strategy, confidence_level, n_resamples, device, random_state, input_column, label_column, label_mapping)\u001B[0m\n\u001B[1;32m    253\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    254\u001B[0m         \u001B[0;31m# Compute predictions\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 255\u001B[0;31m         \u001B[0mpredictions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mperf_results\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall_pipeline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpipe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpipe_inputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    256\u001B[0m         \u001B[0mpredictions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredictions_processor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel_mapping\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    257\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/evaluate/evaluator/base.py\u001B[0m in \u001B[0;36mcall_pipeline\u001B[0;34m(self, pipe, *args, **kwargs)\u001B[0m\n\u001B[1;32m    445\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mcall_pipeline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpipe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    446\u001B[0m         \u001B[0mstart_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mperf_counter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 447\u001B[0;31m         \u001B[0mpipe_output\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpipe\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPIPELINE_KWARGS\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    448\u001B[0m         \u001B[0mend_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mperf_counter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    449\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mpipe_output\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_time_perf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstart_time\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mend_time\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpipe_output\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/final_project/text_generator.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, prompt_s, max_new_tokens, return_tensors, return_text, return_full_text, clean_up_tokenization_spaces, prefix, num_return_sequences, truncation)\u001B[0m\n\u001B[1;32m    290\u001B[0m                 \u001B[0mreturn_full_text\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreturn_full_text\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    291\u001B[0m                 \u001B[0mclean_up_tokenization_spaces\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mclean_up_tokenization_spaces\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 292\u001B[0;31m                 truncation=truncation) for prompt in tqdm(prompt_s)]\n\u001B[0m\u001B[1;32m    293\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    294\u001B[0m         tokenized_prompt: Tensor = self.preprocess(\n",
      "\u001B[0;32m/content/final_project/text_generator.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    290\u001B[0m                 \u001B[0mreturn_full_text\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreturn_full_text\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    291\u001B[0m                 \u001B[0mclean_up_tokenization_spaces\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mclean_up_tokenization_spaces\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 292\u001B[0;31m                 truncation=truncation) for prompt in tqdm(prompt_s)]\n\u001B[0m\u001B[1;32m    293\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    294\u001B[0m         tokenized_prompt: Tensor = self.preprocess(\n",
      "\u001B[0;32m/content/final_project/text_generator.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, prompt_s, max_new_tokens, return_tensors, return_text, return_full_text, clean_up_tokenization_spaces, prefix, num_return_sequences, truncation)\u001B[0m\n\u001B[1;32m    302\u001B[0m             \u001B[0mtokenized_prompt\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    303\u001B[0m             \u001B[0mmax_new_tokens\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 304\u001B[0;31m             \u001B[0mnum_return_sequences\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    305\u001B[0m         )\n\u001B[1;32m    306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/final_project/sampling_generator.py\u001B[0m in \u001B[0;36m_forward\u001B[0;34m(self, tokenized_prompt, num_new_tokens, num_return_sequences)\u001B[0m\n\u001B[1;32m    216\u001B[0m                 \u001B[0mthe_range\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_groups\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    217\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0m_\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mthe_range\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 218\u001B[0;31m                 \u001B[0mprob_mat\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_prob_mat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcurr_token_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    219\u001B[0m                 new_tokens = self.generate_group(\n\u001B[1;32m    220\u001B[0m                     prob_mat, curr_token_list)\n",
      "\u001B[0;32m/content/final_project/sampling_generator.py\u001B[0m in \u001B[0;36mgenerate_group\u001B[0;34m(self, prob_mat, org_used_tokens)\u001B[0m\n\u001B[1;32m    186\u001B[0m             sorted_probs = dict(sorted(\n\u001B[1;32m    187\u001B[0m                 \u001B[0mitems\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 188\u001B[0;31m                 reverse=True))\n\u001B[0m\u001B[1;32m    189\u001B[0m             \u001B[0mweighted_probs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfilter_tokens\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msorted_probs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    190\u001B[0m             \u001B[0mkeys_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweighted_probs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/final_project/sampling_generator.py\u001B[0m in \u001B[0;36mtop_p_tokens\u001B[0;34m(self, sorted_probs)\u001B[0m\n\u001B[1;32m    127\u001B[0m                 \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msorted_probs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    128\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mi\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mcurr_prob\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtop_p\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 129\u001B[0;31m                 \u001B[0mprob_sum\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mcurr_prob\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    130\u001B[0m                 \u001B[0mtop_p_probs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcurr_token\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcurr_prob\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    131\u001B[0m                 \u001B[0;32mcontinue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  }
 ]
}
